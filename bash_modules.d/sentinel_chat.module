#!/usr/bin/env bash
# SENTINEL Chat Module
# Provides conversational AI assistant for shell queries

# Check dependencies
SENTINEL_CHAT_ENABLED=0
if command -v python3 &>/dev/null; then
    # Check for required Python packages
    if python3 -c "import llama_cpp" &>/dev/null && \
       python3 -c "import rich" &>/dev/null; then
        SENTINEL_CHAT_ENABLED=1
    else
        echo "Info: llama-cpp-python or rich not installed."
        echo "To enable SENTINEL Chat, run: sentinel_chat_install_deps"
    fi
else
    echo "Warning: python3 not found. SENTINEL Chat capabilities disabled."
fi

# Path to Chat script
SENTINEL_CHAT_DIR="$(dirname "$(dirname "${BASH_SOURCE[0]}")")/contrib"
SENTINEL_CHAT_SCRIPT="$SENTINEL_CHAT_DIR/sentinel_chat.py"

# Install dependencies for SENTINEL Chat
function sentinel_chat_install_deps() {
    if command -v python3 &>/dev/null; then
        echo "Installing required Python packages..."
        python3 "$SENTINEL_CHAT_SCRIPT" --install-deps
        
        # Check if installation was successful
        if python3 -c "import llama_cpp" &>/dev/null && \
           python3 -c "import rich" &>/dev/null; then
            SENTINEL_CHAT_ENABLED=1
            echo "Dependencies installed successfully."
            echo "SENTINEL Chat is now enabled."
        else
            echo "Error: Failed to install dependencies."
            echo "Please install manually: pip install llama-cpp-python rich readline"
        fi
    else
        echo "Error: python3 not found. Cannot install dependencies."
    fi
}

# Main chat function
function sentinel_chat() {
    if [ $SENTINEL_CHAT_ENABLED -eq 1 ]; then
        # If arguments are provided, use them as a direct query
        if [ $# -gt 0 ]; then
            python3 "$SENTINEL_CHAT_SCRIPT" "$@"
        else
            # Interactive mode
            python3 "$SENTINEL_CHAT_SCRIPT"
        fi
    else
        echo "SENTINEL Chat is not enabled."
        echo "To enable, run: sentinel_chat_install_deps"
    fi
}

# Function to check model status
function sentinel_chat_status() {
    if [ $SENTINEL_CHAT_ENABLED -eq 1 ]; then
        MODEL_DIR=~/.sentinel/models
        CONFIG_FILE=~/.sentinel/chat_config.json
        
        echo "SENTINEL Chat Status:"
        echo "----------------------"
        echo "Enabled: Yes"
        
        if [ -f "$CONFIG_FILE" ]; then
            MODEL_NAME=$(grep "model\":" "$CONFIG_FILE" | cut -d'"' -f4)
            echo "Model: $MODEL_NAME"
            
            if [ -d "$MODEL_DIR" ]; then
                MODEL_PATH="$MODEL_DIR/$MODEL_NAME"
                if [ -f "$MODEL_PATH" ]; then
                    MODEL_SIZE=$(du -h "$MODEL_PATH" | cut -f1)
                    echo "Model size: $MODEL_SIZE"
                    echo "Model path: $MODEL_PATH"
                    echo "Status: Ready"
                else
                    echo "Status: Model not downloaded yet"
                fi
            fi
        else
            echo "Status: Configuration not initialized"
        fi
    else
        echo "SENTINEL Chat Status:"
        echo "----------------------"
        echo "Enabled: No"
        echo "Status: Dependencies not installed"
    fi
}

# Command aliases
alias schat="sentinel_chat"
alias sentinel-chat="sentinel_chat" 