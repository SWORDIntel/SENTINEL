# SENTINEL Python/ML Components Documentation

## Overview

SENTINEL integrates advanced Python-based machine learning and AI capabilities to provide intelligent terminal assistance. These components work seamlessly with the bash environment to offer context-aware suggestions, natural language understanding, and cybersecurity-focused ML features.

## Architecture Overview

```
contrib/
├── Core Intelligence
│   ├── sentinel_autolearn.py      # Adaptive learning system
│   ├── sentinel_context.py        # Context awareness
│   ├── sentinel_suggest.py        # Command suggestions
│   └── sentinel_task_detect.py    # Task detection
│
├── ML/AI Features
│   ├── sentinel_chat.py           # LLM chat interface
│   ├── sentinel_chat_context.py   # Chat context management
│   ├── sentinel_nlu.py            # Natural language processing
│   └── sentinel_chain_predict.py  # Command chain prediction
│
├── Cybersecurity ML
│   └── sentinel_cybersec_ml.py    # Security-focused ML
│
└── OSINT Tools
    ├── sentinel_osint.py          # OSINT data collection
    ├── sentinel_osint_tui.py      # OSINT terminal UI
    ├── sentinel_gitstar.py        # GitHub analysis
    └── sentinel_gitstar_tui.py    # GitStar terminal UI
```

## Core Components

### 1. Adaptive Learning System (sentinel_autolearn.py)

The adaptive learning system monitors user behavior and continuously improves its suggestions and predictions.

#### Features:
- **Command Pattern Learning**: Identifies frequently used command sequences
- **Context-Based Learning**: Learns which commands are used in specific directories/projects
- **Time-Based Patterns**: Recognizes time-of-day and day-of-week patterns
- **Error Correction Learning**: Learns from user corrections

#### Implementation:
```python
class AdaptiveLearner:
    def __init__(self):
        self.command_history = []
        self.context_patterns = {}
        self.correction_map = {}
        
    def learn_from_command(self, command, context):
        # Record command with context
        self.command_history.append({
            'command': command,
            'context': context,
            'timestamp': time.time()
        })
        
        # Update pattern recognition
        self._update_patterns()
        
    def suggest_next_command(self, current_context):
        # Use learned patterns to suggest
        return self._predict_command(current_context)
```

### 2. Context Awareness (sentinel_context.py)

Provides rich context information for intelligent decision-making.

#### Context Dimensions:
- **Working Directory**: Current path and project type
- **Git Status**: Branch, modified files, commit status
- **System State**: Load, memory, active processes
- **User History**: Recent commands and patterns
- **Time Context**: Time of day, day of week

#### Usage:
```python
context = ContextManager()
current_context = context.get_current_context()

# Returns:
{
    'cwd': '/home/user/project',
    'project_type': 'python',
    'git_branch': 'main',
    'recent_commands': [...],
    'system_load': 0.5
}
```

### 3. Intelligent Suggestions (sentinel_suggest.py)

Provides context-aware command suggestions based on multiple factors.

#### Suggestion Sources:
1. **Historical Patterns**: What you've done before in similar contexts
2. **Project Templates**: Common commands for detected project types
3. **Error Recovery**: Suggestions to fix recent errors
4. **Task Completion**: Next steps in multi-command workflows

#### Algorithm:
```python
def generate_suggestions(context):
    suggestions = []
    
    # Historical suggestions
    suggestions.extend(get_historical_suggestions(context))
    
    # Project-specific suggestions
    if context.project_type:
        suggestions.extend(get_project_suggestions(context))
    
    # Error recovery suggestions
    if context.last_error:
        suggestions.extend(get_error_recovery_suggestions(context))
    
    # Rank and filter
    return rank_suggestions(suggestions, context)
```

### 4. Task Detection (sentinel_task_detect.py)

Automatically detects what task the user is trying to accomplish.

#### Detected Tasks:
- **Development Tasks**: Building, testing, debugging
- **System Administration**: Service management, configuration
- **Security Tasks**: Scanning, analysis, exploitation
- **Data Processing**: Analysis, transformation, visualization

#### Task Detection Flow:
```
Recent Commands → Feature Extraction → Task Classification → Confidence Score
                        ↓                      ↓                  ↓
                Command Patterns        ML Classifier      Task Suggestions
```

### 5. LLM Chat Interface (sentinel_chat.py)

Integrates local LLM models for natural language interaction.

#### Supported Models:
- **Ollama**: Various models (llama2, mistral, etc.)
- **GPT4All**: Lightweight models
- **Custom Models**: User-provided models

#### Features:
- **Context-Aware Responses**: Includes shell context in prompts
- **Command Generation**: Generates shell commands from natural language
- **Code Explanation**: Explains complex commands and scripts
- **Error Diagnosis**: Helps debug issues

#### Usage Example:
```bash
$ sentinel-chat "how do I find large files in the current directory?"

Based on your request, here are several ways to find large files:

1. Using 'find' command:
   find . -type f -size +100M

2. Using 'du' command:
   du -h . | grep '[0-9\.]\+G'

3. Using the SENTINEL helper function:
   findlarge 100M

Would you like me to explain any of these commands?
```

### 6. Natural Language Understanding (sentinel_nlu.py)

Processes natural language inputs to understand user intent.

#### NLU Pipeline:
1. **Tokenization**: Break input into tokens
2. **Intent Classification**: Determine user intent
3. **Entity Extraction**: Extract relevant entities
4. **Context Integration**: Combine with system context
5. **Action Generation**: Generate appropriate actions

#### Supported Intents:
- **File Operations**: create, delete, move, find
- **System Commands**: install, update, configure
- **Development**: build, test, deploy
- **Security**: scan, analyze, exploit

### 7. Command Chain Prediction (sentinel_chain_predict.py)

Predicts sequences of commands based on patterns.

#### Chain Types:
- **Build Chains**: compile → test → deploy
- **Debug Chains**: error → investigate → fix → verify
- **Security Chains**: scan → analyze → exploit → report
- **Data Chains**: download → process → analyze → visualize

#### Prediction Model:
```python
class ChainPredictor:
    def __init__(self):
        self.markov_model = MarkovChain()
        self.sequence_model = LSTMModel()
        
    def predict_next(self, command_history):
        # Markov prediction
        markov_pred = self.markov_model.predict(command_history[-3:])
        
        # Deep learning prediction
        lstm_pred = self.sequence_model.predict(command_history[-10:])
        
        # Ensemble prediction
        return self.ensemble_predict(markov_pred, lstm_pred)
```

### 8. Cybersecurity ML (sentinel_cybersec_ml.py)

Specialized ML features for cybersecurity tasks.

#### Security Features:
1. **Threat Detection**: Identifies suspicious patterns
2. **Vulnerability Analysis**: Suggests potential vulnerabilities
3. **Exploit Assistance**: Helps craft exploits safely
4. **Log Analysis**: ML-powered log analysis
5. **Network Anomaly Detection**: Identifies unusual network patterns

#### Security Models:
- **Anomaly Detection**: Isolation Forest, One-Class SVM
- **Classification**: Random Forest for threat classification
- **Sequence Analysis**: RNN for log pattern analysis
- **Clustering**: DBSCAN for grouping similar threats

### 9. OSINT Tools (sentinel_osint.py)

Open Source Intelligence gathering with ML enhancement.

#### OSINT Capabilities:
- **Data Collection**: Multiple source aggregation
- **Entity Recognition**: Automatic entity extraction
- **Relationship Mapping**: Graph-based analysis
- **Pattern Recognition**: Identifying patterns across sources
- **Report Generation**: Automated report creation

#### Data Sources:
- Social media platforms
- Public databases
- DNS records
- Certificate transparency
- Code repositories
- Dark web monitoring

### 10. GitStar System (sentinel_gitstar.py)

Analyzes and categorizes GitHub repositories.

#### Analysis Features:
- **Repository Classification**: Automatic categorization
- **Security Scanning**: Identifies security tools and vulnerabilities
- **Code Quality**: Analyzes code quality metrics
- **Popularity Tracking**: Monitors stars, forks, issues
- **Recommendation Engine**: Suggests similar repositories

#### GitStar Workflow:
```
Repository Discovery → README Analysis → Feature Extraction → Classification
         ↓                    ↓                ↓                  ↓
    GitHub API         NLP Processing    Code Analysis    Category Assignment
```

## Integration with Bash Modules

### Module Communication

Python components communicate with bash through:

1. **Named Pipes**: For real-time communication
2. **JSON IPC**: Structured data exchange
3. **Environment Variables**: Configuration sharing
4. **File-based IPC**: For large data transfers

### Example Integration:

```bash
# In bash module
sentinel_ml_suggest() {
    local context=$(get_current_context)
    local suggestions=$(python3 $SENTINEL_PATH/contrib/sentinel_suggest.py "$context")
    echo "$suggestions"
}

# Python component
import sys
import json

def main():
    context = json.loads(sys.argv[1])
    suggestions = generate_suggestions(context)
    print(json.dumps(suggestions))
```

## Configuration

### Python Component Configuration

Configuration file: `~/.sentinel/ml_config.yaml`

```yaml
ml_components:
  autolearn:
    enabled: true
    history_size: 10000
    learning_rate: 0.01
    
  chat:
    model: "llama2:7b"
    context_size: 4096
    temperature: 0.7
    
  cybersec:
    threat_detection: true
    anomaly_threshold: 0.95
    
  osint:
    sources:
      - github
      - shodan
      - certstream
    rate_limit: 100
```

### Environment Variables

```bash
# ML Component Settings
export SENTINEL_ML_ENABLED=true
export SENTINEL_ML_MODEL_PATH="$HOME/.sentinel/models"
export SENTINEL_ML_CACHE_SIZE=1000
export SENTINEL_ML_BATCH_SIZE=32

# Chat Settings
export SENTINEL_CHAT_MODEL="mistral"
export SENTINEL_CHAT_CONTEXT=true

# OSINT Settings
export SENTINEL_OSINT_TIMEOUT=30
export SENTINEL_OSINT_MAX_RESULTS=100
```

## Performance Optimization

### 1. Model Caching
- Pre-loaded models in memory
- Model quantization for faster inference
- Caching frequent predictions

### 2. Batch Processing
- Group similar requests
- Parallel processing where possible
- Async operation for non-blocking behavior

### 3. Resource Management
- CPU/GPU detection and utilization
- Memory-efficient data structures
- Automatic garbage collection

## Security Considerations

### 1. Data Privacy
- Local-only processing by default
- No telemetry without consent
- Encrypted storage for sensitive data

### 2. Model Security
- Sandboxed execution
- Input validation
- Output sanitization

### 3. API Security
- Rate limiting
- Authentication for external APIs
- Secure credential storage

## Troubleshooting

### Common Issues

1. **Model Loading Errors**
   ```bash
   # Check model path
   ls -la $SENTINEL_ML_MODEL_PATH
   
   # Verify Python dependencies
   pip check -r requirements.txt
   ```

2. **Performance Issues**
   ```bash
   # Enable profiling
   export SENTINEL_ML_PROFILE=true
   
   # Check resource usage
   sentinel ml status
   ```

3. **Integration Problems**
   ```bash
   # Test Python components
   python3 contrib/test_ml_components.py
   
   # Check IPC
   sentinel ml test-ipc
   ```

## Development Guide

### Adding New ML Components

1. **Create Component File**
   ```python
   # contrib/sentinel_myfeature.py
   
   from sentinel_base import SentinelComponent
   
   class MyFeature(SentinelComponent):
       def __init__(self):
           super().__init__("myfeature")
           
       def process(self, input_data):
           # Implementation
           return result
   ```

2. **Register Component**
   ```python
   # In __init__.py
   from .sentinel_myfeature import MyFeature
   
   COMPONENTS = {
       'myfeature': MyFeature
   }
   ```

3. **Create Bash Integration**
   ```bash
   # In module file
   sentinel_myfeature() {
       python3 $SENTINEL_PATH/contrib/run_component.py myfeature "$@"
   }
   ```

## Future Enhancements

1. **Advanced Models**
   - Transformer-based command prediction
   - Multi-modal analysis (text + system state)
   - Federated learning for privacy

2. **Enhanced Integration**
   - Real-time streaming predictions
   - GPU acceleration
   - Distributed processing

3. **New Capabilities**
   - Voice interaction
   - Visual terminal analysis
   - Automated workflow generation

## Conclusion

The Python/ML components provide SENTINEL with powerful intelligence capabilities while maintaining security and performance. These components work together to create an adaptive, context-aware terminal experience that learns and improves over time.